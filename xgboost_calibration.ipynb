{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# XGBoost Model Calibration\n",
        "\n",
        "This notebook contains cells extracted from `xgboost_evaluation.ipynb`, focusing on model calibration techniques and their evaluation."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import xgboost as xgb\n",
        "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score, roc_curve, auc, roc_auc_score, precision_recall_fscore_support\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import numpy as np\n",
        "from sklearn.calibration import CalibrationDisplay, CalibratedClassifierCV\n",
        "from sklearn.model_selection import cross_val_score, StratifiedKFold"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "bc90cbbe",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Define input path\n",
        "input_parquet_path = 'data/preprocessed_data.parquet'\n",
        "# Load the preprocessed data\n",
        "print(f\"Loading preprocessed data from {input_parquet_path}...\")\n",
        "try:\n",
        "    df = pd.read_parquet(input_parquet_path)\n",
        "    print(\"Data loaded successfully.\")\n",
        "    df.info()\n",
        "except FileNotFoundError:\n",
        "    print(f\"Error: File not found at {input_parquet_path}. Please ensure '1_consolidate_data.ipynb' has been run.\")\n",
        "except Exception as e:\n",
        "    print(f\"\\nAn error occurred while loading the Parquet file: {e}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b30a19d4",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Separate train and test sets based on the 'split' column\n",
        "train_df = df[df['split'] == 'train']\n",
        "test_df = df[df['split'] == 'test']\n",
        "\n",
        "# Separate features (X) and target (y)\n",
        "X_train_scaled = train_df.drop(['Class', 'split'], axis=1)\n",
        "y_train = train_df['Class']\n",
        "\n",
        "X_test_scaled = test_df.drop(['Class', 'split'], axis=1)\n",
        "y_test = test_df['Class']\n",
        "\n",
        "print(f\"Training features shape: {X_train_scaled.shape}, Training target shape: {y_train.shape}\")\n",
        "print(f\"Test features shape: {X_test_scaled.shape}, Test target shape: {y_test.shape}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1391e7f0",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Convert target variable 'Class' from object ('n'/'y') to numeric (0/1) if necessary\n",
        "if y_train.dtype == 'object':\n",
        "    print(\"\\nConverting target variable 'Class' to numeric (n=0, y=1)...\")\n",
        "    y_train = y_train.map({'n': 0, 'y': 1})\n",
        "    y_test = y_test.map({'n': 0, 'y': 1})\n",
        "    print(\"Target variable converted.\")\n",
        "else:\n",
        "    print(\"\\nTarget variable 'Class' is already numeric or in an unexpected format.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9efd48a3",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Calculate class distribution in the training set for scale_pos_weight\n",
        "scale_pos_weight_val = 1 # Default\n",
        "if y_train.dtype == 'int64' or y_train.dtype == 'int32':\n",
        "    count_class_0 = (y_train == 0).sum()\n",
        "    count_class_1 = (y_train == 1).sum()\n",
        "    print(f\"\\nTraining data class distribution: Class 0 (n): {count_class_0}, Class 1 (y): {count_class_1}\")\n",
        "    if count_class_1 > 0:\n",
        "        scale_pos_weight_val = count_class_0 / count_class_1\n",
        "        print(f\"Calculated scale_pos_weight: {scale_pos_weight_val:.4f}\")\n",
        "    else:\n",
        "        print(\"Warning: No positive class (1) instances in y_train. scale_pos_weight set to 1.\")\n",
        "else:\n",
        "    print(f\"Warning: y_train is not numeric (dtype: {y_train.dtype}). scale_pos_weight set to 1.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "19997a0e",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Define and Train XGBoost Classifier\n",
        "xgb_clf = xgb.XGBClassifier(\n",
        "    objective='binary:logistic',\n",
        "    eval_metric='logloss',\n",
        "    use_label_encoder=False, # Recommended to avoid warnings\n",
        "    random_state=42,\n",
        "    n_estimators=100, # Default, can be tuned\n",
        "    scale_pos_weight=scale_pos_weight_val\n",
        ")\n",
        "\n",
        "xgb_clf.fit(X_train_scaled, y_train)\n",
        "print(\"Model training complete.\")\n",
        "\n",
        "\n",
        "n_splits_cv = 3 # Reduced for dummy example\n",
        "strat_k_fold = StratifiedKFold(n_splits=n_splits_cv, shuffle=True, random_state=42)\n",
        "scoring_metrics = {\n",
        "    'accuracy': 'accuracy',\n",
        "    'roc_auc': 'roc_auc',\n",
        "    'f1': 'f1_weighted'\n",
        "}\n",
        "\n",
        "print(\"--- Placeholder variables defined ---\")\n",
        "print(f\"X_train_scaled shape: {X_train_scaled.shape}, y_train shape: {y_train.shape}\")\n",
        "print(f\"X_test_scaled shape: {X_test_scaled.shape}, y_test shape: {y_test.shape}\")\n",
        "print(f\"xgb_clf: {type(xgb_clf)}\")\n",
        "print(f\"scale_pos_weight_val: {scale_pos_weight_val}\")\n",
        "# --- End of Placeholder ---"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "473cebbf",
      "metadata": {},
      "outputs": [],
      "source": [
        "def evaluate_model(y_true, y_pred, X_features_for_proba, model, model_name):\n",
        "    \"\"\"Calculates, prints, and plots evaluation metrics for a binary classifier.\"\"\"\n",
        "    print(f\"\\n--- {model_name} Evaluation ---\")\n",
        "    \n",
        "    # Accuracy\n",
        "    accuracy = accuracy_score(y_true, y_pred)\n",
        "    print(f\"Accuracy: {accuracy:.4f}\")\n",
        "    \n",
        "    # Classification Report\n",
        "    print(\"\\nClassification Report:\")\n",
        "    target_names = ['Class n (0)', 'Class y (1)'] if np.all(np.isin(y_true.unique(), [0, 1])) else None\n",
        "    print(classification_report(y_true, y_pred, target_names=target_names, zero_division=0))\n",
        "    \n",
        "    # Confusion Matrix\n",
        "    print(\"\\nConfusion Matrix:\")\n",
        "    cm = confusion_matrix(y_true, y_pred)\n",
        "    print(cm)\n",
        "    \n",
        "    # Plot Confusion Matrix\n",
        "    plt.figure(figsize=(6, 4))\n",
        "    classes = model.classes_ if hasattr(model, 'classes_') else [0, 1]\n",
        "    sns.heatmap(cm, annot=True, fmt='d', cmap='Greens', \n",
        "                xticklabels=classes, \n",
        "                yticklabels=classes)\n",
        "    plt.xlabel('Predicted Label')\n",
        "    plt.ylabel('True Label')\n",
        "    plt.title(f'Confusion Matrix - {model_name}')\n",
        "    plt.show()\n",
        "\n",
        "    # ROC Curve and AUC\n",
        "    if hasattr(model, \"predict_proba\") and X_features_for_proba is not None:\n",
        "        y_pred_proba = model.predict_proba(X_features_for_proba)[:, 1]\n",
        "        fpr, tpr, thresholds_roc = roc_curve(y_true, y_pred_proba)\n",
        "        roc_auc = auc(fpr, tpr)\n",
        "        print(f\"\\nROC AUC Score: {roc_auc:.4f}\")\n",
        "\n",
        "        plt.figure(figsize=(8, 6))\n",
        "        plt.plot(fpr, tpr, color='darkorange', lw=2, label=f'ROC curve (area = {roc_auc:.2f})')\n",
        "        plt.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--')\n",
        "        plt.xlim([0.0, 1.0])\n",
        "        plt.ylim([0.0, 1.05])\n",
        "        plt.xlabel('False Positive Rate')\n",
        "        plt.ylabel('True Positive Rate')\n",
        "        plt.title(f'Receiver Operating Characteristic (ROC) - {model_name}')\n",
        "        plt.legend(loc=\"lower right\")\n",
        "        plt.show()\n",
        "    else:\n",
        "        print(\"\\nROC Curve not available: Model lacks predict_proba or features for probabilities not provided.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "dbae965b",
      "metadata": {},
      "source": [
        "## Note on Dependencies\n",
        "\n",
        "The following cells depend on variables defined and computed in the earlier parts of the `xgboost_evaluation.ipynb` notebook. To run this notebook independently, you will need to ensure the following (and their own dependencies) are defined and available in the kernel:\n",
        "\n",
        "- `X_train_scaled`: Scaled training features.\n",
        "- `y_train`: Training target.\n",
        "- `X_test_scaled`: Scaled test features.\n",
        "- `y_test`: Test target.\n",
        "- `xgb_clf`: The initially trained (uncalibrated) XGBoost model.\n",
        "- `scale_pos_weight_val`: Value for `scale_pos_weight` used in XGBoost.\n",
        "- `threshold_values`: NumPy array of thresholds for tuning.\n",
        "- `n_splits_cv`: Integer, number of CV splits.\n",
        "- `strat_k_fold`: An instance of `StratifiedKFold`.\n",
        "- `scoring_metrics`: Dictionary defining scoring for CV.\n",
        "\n",
        "These are typically prepared during data loading, preprocessing, and initial model training phases."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "5eb455b3",
      "metadata": {},
      "source": [
        "## Model Calibration Analysis\n",
        "\n",
        "A calibration curve (also known as a reliability diagram) helps to assess how well the probabilistic predictions of a classifier are calibrated.\n",
        "Ideally, if a model predicts a class with a probability of `p`, then among all instances where it predicts `p`, approximately `p * 100%` of them should actually belong to that class.\n",
        "A perfectly calibrated model will have a curve that lies along the diagonal.\n",
        "\n",
        "\n",
        "A bias in the training dataset, such as a skew in the class distribution, means that the model will naturally predict a higher probability for the majority class than the minority class on average."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "abdf294b",
      "metadata": {},
      "outputs": [],
      "source": [
        "from sklearn.calibration import CalibrationDisplay\n",
        "\n",
        "\n",
        "print(\"\\n--- Model Calibration Analysis ---\")\n",
        "\n",
        "\n",
        "# Display calibration curve\n",
        "plt.figure(figsize=(8, 7))\n",
        "ax_calibration = plt.gca() # Get current axes\n",
        "calibration_disp = CalibrationDisplay.from_estimator(\n",
        "    xgb_clf,\n",
        "    X_test_scaled,\n",
        "    y_test,\n",
        "    n_bins=10, # Number of bins to discretize the [0, 1] interval\n",
        "    ax=ax_calibration,\n",
        "    name='XGBoost'\n",
        ")\n",
        "plt.title('Calibration Curve (Reliability Diagram)')\n",
        "plt.grid(True)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "681cfec1",
      "metadata": {},
      "source": [
        "### Applying Platt Scaling (Sigmoid Calibration)\n",
        "\n",
        "\n",
        "Since the initial calibration curve might not be perfectly diagonal, we can attempt to improve it using Platt Scaling. This method trains a logistic regression model on the outputs of the original XGBoost classifier to produce better-calibrated probabilities.\n",
        "\n",
        "\n",
        "We will use `CalibratedClassifierCV` with `method='sigmoid'` to apply Platt Scaling. The calibrator will be trained using cross-validation on the training data."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Applying Isotonic Regression Calibration\n",
        "\n",
        "\n",
        "Isotonic Regression is another method to calibrate probabilities. Unlike Platt Scaling, which assumes a sigmoid relationship, Isotonic Regression is non-parametric and fits a non-decreasing function. It can be more powerful if the distortion is not sigmoid-shaped, but may require more data to avoid overfitting.\n",
        "\n",
        "\n",
        "We will use `CalibratedClassifierCV` with `method='isotonic'`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from sklearn.calibration import CalibratedClassifierCV\n",
        "\n",
        "\n",
        "print(\"\\n--- Applying Platt Scaling and Isotonic Regression ---\")\n",
        "\n",
        "\n",
        "# --- Platt Scaling (Sigmoid) --- \n",
        "base_clf_for_sigmoid = xgb.XGBClassifier(\n",
        "    objective='binary:logistic',\n",
        "    eval_metric='logloss',\n",
        "    use_label_encoder=False, \n",
        "    random_state=42,\n",
        "    n_estimators=100,\n",
        "    scale_pos_weight=scale_pos_weight_val\n",
        ")\n",
        "calibrated_xgb_clf_sigmoid = CalibratedClassifierCV(\n",
        "    estimator=base_clf_for_sigmoid, \n",
        "    method='sigmoid', \n",
        "    cv=5\n",
        ")\n",
        "print(\"Fitting CalibratedClassifierCV with Platt Scaling...\")\n",
        "calibrated_xgb_clf_sigmoid.fit(X_train_scaled, y_train)\n",
        "print(\"Platt Scaling fitting complete.\")\n",
        "\n",
        "\n",
        "# --- Isotonic Regression --- \n",
        "base_clf_for_isotonic = xgb.XGBClassifier(\n",
        "    objective='binary:logistic',\n",
        "    eval_metric='logloss',\n",
        "    use_label_encoder=False, \n",
        "    random_state=42,\n",
        "    n_estimators=100,\n",
        "    scale_pos_weight=scale_pos_weight_val\n",
        ")\n",
        "calibrated_xgb_clf_isotonic = CalibratedClassifierCV(\n",
        "    estimator=base_clf_for_isotonic, \n",
        "    method='isotonic', \n",
        "    cv=5 \n",
        ")\n",
        "print(\"\\nFitting CalibratedClassifierCV with Isotonic Regression...\")\n",
        "calibrated_xgb_clf_isotonic.fit(X_train_scaled, y_train)\n",
        "print(\"Isotonic Regression fitting complete.\")\n",
        "\n",
        "\n",
        "# --- Display comparative calibration curves --- \n",
        "plt.figure(figsize=(10, 9))\n",
        "ax_calibrated = plt.gca()\n",
        "print(\"\\nPlotting calibration curves...\")\n",
        "CalibrationDisplay.from_estimator(\n",
        "    xgb_clf, \n",
        "    X_test_scaled, \n",
        "    y_test, \n",
        "    ax=ax_calibrated, \n",
        "    name='XGBoost (Uncalibrated)', \n",
        "    n_bins=10\n",
        ")\n",
        "CalibrationDisplay.from_estimator(\n",
        "    calibrated_xgb_clf_sigmoid, \n",
        "    X_test_scaled, \n",
        "    y_test, \n",
        "    ax=ax_calibrated, \n",
        "    name='XGBoost (Platt Scaled)',\n",
        "    n_bins=10\n",
        ")\n",
        "CalibrationDisplay.from_estimator(\n",
        "    calibrated_xgb_clf_isotonic, \n",
        "    X_test_scaled, \n",
        "    y_test, \n",
        "    ax=ax_calibrated, \n",
        "    name='XGBoost (Isotonic)',\n",
        "    n_bins=10\n",
        ")\n",
        "plt.title('Calibration Curve: Uncalibrated vs. Platt Scaled vs. Isotonic XGBoost')\n",
        "plt.xlabel('Mean Predicted Probability (Positive Class)')\n",
        "plt.ylabel('Fraction of Positives')\n",
        "plt.grid(True)\n",
        "plt.legend(loc='lower right')\n",
        "plt.show()\n",
        "\n",
        "print(\"Calibration plot displayed.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "print(\"\\n--- Evaluating Platt Scaled Model ---\")\n",
        "y_pred_platt_calibrated = calibrated_xgb_clf_sigmoid.predict(X_test_scaled)\n",
        "evaluate_model(y_test, y_pred_platt_calibrated, X_test_scaled, calibrated_xgb_clf_sigmoid, \"XGBoost (Platt Scaled)\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "print(\"\\n--- Evaluating Isotonic Regression Calibrated Model ---\")\n",
        "y_pred_isotonic_calibrated = calibrated_xgb_clf_isotonic.predict(X_test_scaled)\n",
        "evaluate_model(y_test, y_pred_isotonic_calibrated, X_test_scaled, calibrated_xgb_clf_isotonic, \"XGBoost (Isotonic)\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Cross-Validation of Isotonic Regression Calibrated Model\n",
        "\n",
        "\n",
        "To get a more robust estimate of the Isotonic Regression calibrated model's performance and ensure the improvements are not due to a specific train-test split during the calibration phase, we perform an outer cross-validation on the entire `CalibratedClassifierCV` process. This involves fitting the `CalibratedClassifierCV` (which itself uses internal CV for calibration) on different folds of the training data."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "print(\"\\n--- Cross-Validation for Isotonic Regression Calibrated XGBoost ---\")\n",
        "\n",
        "\n",
        "# Define a fresh base XGBoost classifier for the CalibratedClassifierCV\n",
        "# This is crucial because CalibratedClassifierCV will fit this estimator internally during its own CV process.\n",
        "base_clf_for_cv_isotonic = xgb.XGBClassifier(\n",
        "    objective='binary:logistic',\n",
        "    eval_metric='logloss',\n",
        "    use_label_encoder=False, \n",
        "    random_state=42,\n",
        "    n_estimators=100,\n",
        "    scale_pos_weight=scale_pos_weight_val\n",
        ")\n",
        "\n",
        "\n",
        "# Create the CalibratedClassifierCV with Isotonic Regression for the outer cross-validation\n",
        "# The 'cv=5' (or another integer) inside CalibratedClassifierCV is for its internal calibration process.\n",
        "# The 'cv=strat_k_fold' in cross_val_score is for the outer performance evaluation loop.\n",
        "cv_calibrated_xgb_clf_isotonic = CalibratedClassifierCV(\n",
        "    estimator=base_clf_for_cv_isotonic, \n",
        "    method='isotonic', \n",
        "    cv=5 # Internal CV for calibration. Could be different from outer CV folds.\n",
        ")\n",
        "\n",
        "\n",
        "print(f\"Performing {n_splits_cv}-fold outer cross-validation on the Isotonic Calibrated model...\")\n",
        "print(\"(Note: CalibratedClassifierCV also performs internal CV for calibration on each outer fold)\")\n",
        "\n",
        "\n",
        "cv_results_isotonic_calibrated = {}\n",
        "for metric_name, scorer in scoring_metrics.items():\n",
        "    try:\n",
        "        # We use strat_k_fold (defined earlier for uncalibrated model CV) for the outer cross-validation loop\n",
        "        scores = cross_val_score(cv_calibrated_xgb_clf_isotonic, X_train_scaled, y_train, cv=strat_k_fold, scoring=scorer)\n",
        "        cv_results_isotonic_calibrated[metric_name] = scores\n",
        "        print(f\"Outer CV {metric_name.upper()} scores (Isotonic Calibrated): {scores}\")\n",
        "        print(f\"Mean Outer CV {metric_name.upper()} (Isotonic Calibrated): {np.mean(scores):.4f} (+/- {np.std(scores):.4f})\")\n",
        "    except Exception as e:\n",
        "        print(f\"Could not calculate outer CV {metric_name.upper()} (Isotonic Calibrated). Error: {e}\")\n",
        "    print(\"-\" * 30)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Threshold Tuning for Isotonic Calibrated Model (Class n (0))\n",
        "\n",
        "\n",
        "Since Isotonic calibration alters the model's probability outputs, it's beneficial to re-evaluate the optimal classification threshold for our specific needs (e.g., maximizing F1-score for Class 0) using these new, calibrated probabilities."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Get predicted probabilities for the positive class (Class 1, 'y') from the ISOTONIC CALIBRATED xgb_clf\n",
        "# The calibrated_xgb_clf_isotonic model should already be fitted from the previous calibration cell.\n",
        "y_pred_proba_isotonic_calibrated = calibrated_xgb_clf_isotonic.predict_proba(X_test_scaled)[:, 1]\n",
        "\n",
        "# Define a range of threshold values to test\n",
        "threshold_values = np.arange(0.05, 1.0, 0.05)\n",
        "\n",
        "precisions_class0_isotonic = []\n",
        "recalls_class0_isotonic = []\n",
        "f1s_class0_isotonic = []\n",
        "\n",
        "\n",
        "print(\"\\n--- Threshold Tuning for Class n (0) (Isotonic Calibrated Model) ---\")\n",
        "print(f\"{'Threshold':<10} | {'Precision (0)':<15} | {'Recall (0)':<12} | {'F1-score (0)':<12} | {'TP (0)':<7} | {'FP (0)':<7} | {'FN (0)':<7}\")\n",
        "print(\"-\" * 80)\n",
        "\n",
        "\n",
        "# threshold_values is already defined from the earlier threshold tuning section\n",
        "for thresh_iso in threshold_values:\n",
        "    # If prob_for_class_1 >= threshold, predict 1 (y), else 0 (n)\n",
        "    y_pred_at_threshold_isotonic = (y_pred_proba_isotonic_calibrated >= thresh_iso).astype(int)\n",
        "    \n",
        "    # Calculate metrics for Class 0 (label 0)\n",
        "    p_iso, r_iso, f_iso, s_iso = precision_recall_fscore_support(y_test, y_pred_at_threshold_isotonic, labels=[0, 1], zero_division=0)\n",
        "    \n",
        "    # Confusion matrix for this threshold to get TP, FP, FN for class 0\n",
        "    cm_thresh_isotonic = confusion_matrix(y_test, y_pred_at_threshold_isotonic, labels=[0,1])\n",
        "    tp_c0_iso = cm_thresh_isotonic[0,0] if cm_thresh_isotonic.shape == (2,2) else 0\n",
        "    fp_c0_iso = cm_thresh_isotonic[1,0] if cm_thresh_isotonic.shape == (2,2) else 0 \n",
        "    fn_c0_iso = cm_thresh_isotonic[0,1] if cm_thresh_isotonic.shape == (2,2) else 0\n",
        "\n",
        "    precisions_class0_isotonic.append(p_iso[0])\n",
        "    recalls_class0_isotonic.append(r_iso[0])\n",
        "    f1s_class0_isotonic.append(f_iso[0])\n",
        "    \n",
        "    print(f\"{thresh_iso:<10.2f} | {p_iso[0]:<15.4f} | {r_iso[0]:<12.4f} | {f_iso[0]:<12.4f} | {tp_c0_iso:<7} | {fp_c0_iso:<7} | {fn_c0_iso:<7}\")\n",
        "\n",
        "\n",
        "# Plotting the metrics for Isotonic Calibrated Model\n",
        "plt.figure(figsize=(12, 7))\n",
        "plt.plot(threshold_values, precisions_class0_isotonic, label='Precision (Class 0 - Isotonic Cal.)', marker='o')\n",
        "plt.plot(threshold_values, recalls_class0_isotonic, label='Recall (Class 0 - Isotonic Cal.)', marker='x')\n",
        "plt.plot(threshold_values, f1s_class0_isotonic, label='F1-score (Class 0 - Isotonic Cal.)', marker='s')\n",
        "plt.title('Precision, Recall, and F1-score for Class n (0) vs. Threshold (Isotonic Calibrated Model)')\n",
        "plt.xlabel('Threshold (Probability for Class y (1))')\n",
        "plt.ylabel('Score')\n",
        "plt.xticks(np.round(threshold_values,2))\n",
        "plt.legend()\n",
        "plt.grid(True)\n",
        "plt.show()\n",
        "\n",
        "\n",
        "# Find threshold that maximizes F1-score for Class 0 for Isotonic Calibrated Model\n",
        "if f1s_class0_isotonic and not all(v == 0 for v in f1s_class0_isotonic):\n",
        "    optimal_idx_f1_class0_isotonic = np.argmax(f1s_class0_isotonic)\n",
        "    optimal_threshold_f1_class0_isotonic = threshold_values[optimal_idx_f1_class0_isotonic]\n",
        "    print(f\"\\nOptimal threshold for maximizing F1-score for Class n (0) (Isotonic Calibrated Model): {optimal_threshold_f1_class0_isotonic:.2f}\")\n",
        "    print(f\"  Precision (Class 0) at this threshold: {precisions_class0_isotonic[optimal_idx_f1_class0_isotonic]:.4f}\")\n",
        "    print(f\"  Recall (Class 0) at this threshold: {recalls_class0_isotonic[optimal_idx_f1_class0_isotonic]:.4f}\")\n",
        "    print(f\"  F1-score (Class 0) at this threshold: {f1s_class0_isotonic[optimal_idx_f1_class0_isotonic]:.4f}\")\n",
        "else:\n",
        "    print(\"\\nCould not determine optimal threshold for F1-score (Class 0) (Isotonic Calibrated Model) as no valid F1 scores were calculated or all were zero.\")"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
