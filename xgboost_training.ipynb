{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Task 4: Binary Classification - XGBoost Model\n",
        "\n",
        "This notebook loads the preprocessed data saved by `1_consolidate_data.ipynb` and trains/evaluates an XGBoost classifier.\n",
        "\n",
        "\n",
        "\n",
        "XGBoost (Extreme Gradient Boosting) is a powerful and often high-performing algorithm for classification tasks."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import xgboost as xgb\n",
        "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score, roc_curve, auc, roc_auc_score, precision_recall_fscore_support\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import numpy as np # For potential NaN handling if needed, though imputation should handle it"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Define input path\n",
        "input_parquet_path = 'data/preprocessed_data.parquet'\n",
        "# Load the preprocessed data\n",
        "print(f\"Loading preprocessed data from {input_parquet_path}...\")\n",
        "try:\n",
        "    df = pd.read_parquet(input_parquet_path)\n",
        "    print(\"Data loaded successfully.\")\n",
        "    print(\"\\nLoaded DataFrame Info:\")\n",
        "    df.info()\n",
        "except FileNotFoundError:\n",
        "    print(f\"Error: File not found at {input_parquet_path}. Please run notebook 1 first.\")\n",
        "    # raise\n",
        "except ImportError as e:\n",
        "    print(f\"\\nError: 'pyarrow' or 'fastparquet' package is required to read Parquet format, or 'xgboost' is missing.\")\n",
        "    print(\"Please install required packages using: pip install pyarrow xgboost\")\n",
        "    # raise\n",
        "except Exception as e:\n",
        "    print(f\"\\nAn error occurred while loading the Parquet file: {e}\")\n",
        "    # raise"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Separate train and test sets based on the 'split' column\n",
        "train_df = df[df['split'] == 'train']\n",
        "test_df = df[df['split'] == 'test']\n",
        "\n",
        "# Separate features (X) and target (y)\n",
        "X_train_scaled = train_df.drop(['Class', 'split'], axis=1)\n",
        "y_train = train_df['Class']\n",
        "\n",
        "X_test_scaled = test_df.drop(['Class', 'split'], axis=1)\n",
        "y_test = test_df['Class']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Convert target variable 'Class' from object ('n'/'y') to numeric (0/1) if necessary\n",
        "if y_train.dtype == 'object':\n",
        "    print(\"\\nConverting target variable 'Class' to numeric (n=0, y=1)...\")\n",
        "    y_train = y_train.map({'n': 0, 'y': 1})\n",
        "    y_test = y_test.map({'n': 0, 'y': 1})\n",
        "    print(\"Target variable converted.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "print(f\"\\nTraining features shape: {X_train_scaled.shape}\")\n",
        "print(f\"Training target shape: {y_train.shape}\")\n",
        "print(f\"Test features shape: {X_test_scaled.shape}\")\n",
        "print(f\"Test target shape: {y_test.shape}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Calculate class distribution in the training set for scale_pos_weight\n",
        "if y_train.dtype == 'int64' or y_train.dtype == 'int32': # Ensure y_train is numeric\n",
        "    count_class_0 = (y_train == 0).sum()\n",
        "    count_class_1 = (y_train == 1).sum()\n",
        "    print(f\"\\nTraining data class distribution: Class 0 (n): {count_class_0}, Class 1 (y): {count_class_1}\")\n",
        "    if count_class_1 > 0: # Avoid division by zero\n",
        "        scale_pos_weight_val = count_class_0 / count_class_1\n",
        "        print(f\"Calculated scale_pos_weight: {scale_pos_weight_val:.4f}\")\n",
        "    else:\n",
        "        scale_pos_weight_val = 1 # Default if no positive class instances\n",
        "        print(\"Warning: No positive class (1) instances in y_train. scale_pos_weight set to 1.\")\n",
        "else:\n",
        "    scale_pos_weight_val = 1 # Default if y_train is not in expected numeric format\n",
        "    print(f\"Warning: y_train is not numeric. dtype: {y_train.dtype}. scale_pos_weight set to 1.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "xgb_clf = xgb.XGBClassifier(\n",
        "    objective='binary:logistic',\n",
        "    eval_metric='logloss',\n",
        "    use_label_encoder=False, # Recommended to avoid warnings\n",
        "    random_state=42,\n",
        "    n_estimators=100, # Default, can be tuned\n",
        "    scale_pos_weight=scale_pos_weight_val # Add calculated scale_pos_weight\n",
        ")\n",
        "\n",
        "# Train the model\n",
        "print(\"\\nTraining XGBoost model...\")\n",
        "xgb_clf.fit(X_train_scaled, y_train)\n",
        "print(\"Model training complete.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Make Predictions\n",
        "y_pred_xgb = xgb_clf.predict(X_test_scaled)\n",
        "# Make Predictions on the test set\n",
        "# y_pred_proba_xgb = xgb_clf.predict_proba(X_test_scaled)[:, 1] # Probabilities (optional)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "bd1f7c80",
      "metadata": {},
      "outputs": [],
      "source": [
        "def evaluate_model(y_true, y_pred, X_features_for_proba, model, model_name):\n",
        "    \"\"\"Calculates, prints, and plots evaluation metrics for a binary classifier.\"\"\"\n",
        "    print(f\"\\n--- {model_name} Evaluation ---\")\n",
        "    \n",
        "    # Accuracy\n",
        "    accuracy = accuracy_score(y_true, y_pred)\n",
        "    print(f\"Accuracy: {accuracy:.4f}\")\n",
        "    \n",
        "    # Classification Report\n",
        "    print(\"\\nClassification Report:\")\n",
        "    target_names = ['Class n (0)', 'Class y (1)'] if np.all(np.isin(y_true.unique(), [0, 1])) else None\n",
        "    print(classification_report(y_true, y_pred, target_names=target_names, zero_division=0))\n",
        "    \n",
        "    # Confusion Matrix\n",
        "    print(\"\\nConfusion Matrix:\")\n",
        "    cm = confusion_matrix(y_true, y_pred)\n",
        "    print(cm)\n",
        "    \n",
        "    # Plot Confusion Matrix\n",
        "    plt.figure(figsize=(6, 4))\n",
        "    classes = model.classes_ if hasattr(model, 'classes_') else [0, 1]\n",
        "    sns.heatmap(cm, annot=True, fmt='d', cmap='Greens', \n",
        "                xticklabels=classes, \n",
        "                yticklabels=classes)\n",
        "    plt.xlabel('Predicted Label')\n",
        "    plt.ylabel('True Label')\n",
        "    plt.title(f'Confusion Matrix - {model_name}')\n",
        "    plt.show()\n",
        "\n",
        "    # ROC Curve and AUC\n",
        "    if hasattr(model, \"predict_proba\") and X_features_for_proba is not None:\n",
        "        y_pred_proba = model.predict_proba(X_features_for_proba)[:, 1]\n",
        "        fpr, tpr, thresholds_roc = roc_curve(y_true, y_pred_proba)\n",
        "        roc_auc = auc(fpr, tpr)\n",
        "        print(f\"\\nROC AUC Score: {roc_auc:.4f}\")\n",
        "\n",
        "        plt.figure(figsize=(8, 6))\n",
        "        plt.plot(fpr, tpr, color='darkorange', lw=2, label=f'ROC curve (area = {roc_auc:.2f})')\n",
        "        plt.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--')\n",
        "        plt.xlim([0.0, 1.0])\n",
        "        plt.ylim([0.0, 1.05])\n",
        "        plt.xlabel('False Positive Rate')\n",
        "        plt.ylabel('True Positive Rate')\n",
        "        plt.title(f'Receiver Operating Characteristic (ROC) - {model_name}')\n",
        "        plt.legend(loc=\"lower right\")\n",
        "        plt.show()\n",
        "    else:\n",
        "        print(\"\\nROC Curve not available: Model lacks predict_proba or features for probabilities not provided.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c05c74c4",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Evaluate the XGBoost model\n",
        "evaluate_model(y_test, y_pred_xgb, X_test_scaled, xgb_clf, \"XGBoost\")"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.13.2"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
